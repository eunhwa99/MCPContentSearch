import asyncio
import logging
import re
from typing import Tuple
from dataclasses import dataclass

from search.service import SearchService
from fetching.web_searcher import WebSearcher
from indexing.indexer import ContentIndexer
from core.models import DocumentModel

logger = logging.getLogger(__name__)


@dataclass
class SearchResult:
    """ê²€ìƒ‰ ê²°ê³¼"""
    source: str  # "local" | "web"
    results: str
    new_docs_count: int = 0


class DynamicSearchService:
    """
    ë™ì  ê²€ìƒ‰ ì„œë¹„ìŠ¤
    
    1. ë¡œì»¬ DB ê²€ìƒ‰
    2. ê²°ê³¼ ë¶€ì¡± ì‹œ ì›¹ ê²€ìƒ‰
    3. ì›¹ ê²°ê³¼ ìë™ ì¸ë±ì‹±
    """
    
    def __init__(
        self,
        local_search: SearchService,
        web_searcher: WebSearcher,
        indexer: ContentIndexer,
        min_threshold: int = 3
    ):
        self.local_search = local_search
        self.web_searcher = web_searcher
        self.indexer = indexer
        self.min_threshold = min_threshold
    
    async def search(
        self, 
        query: str, 
        n_results: int = 10
    ) -> SearchResult:
        """
        í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ (ë¡œì»¬ â†’ ì›¹)
        
        Args:
            query: ê²€ìƒ‰ì–´
            n_results: ì›í•˜ëŠ” ê²°ê³¼ ìˆ˜
        
        Returns:
            SearchResult
        """
        # 1ë‹¨ê³„: ë¡œì»¬ DB ê²€ìƒ‰
        logger.info(f"ğŸ” Searching local DB for: '{query}'")
        local_results, local_count = await self._search_local(query, n_results)
        
        # ì¶©ë¶„í•œ ê²°ê³¼ê°€ ìˆìœ¼ë©´ ë°˜í™˜
        if local_count >= self.min_threshold:
            logger.info(f"âœ“ Found {local_count} results in local DB")
            return SearchResult(
                source="local",
                results=local_results
            )
        
        # 2ë‹¨ê³„: ì›¹ ê²€ìƒ‰
        logger.info(f"âš  Insufficient results ({local_count}/{self.min_threshold}), searching web...")
        web_docs = await self.web_searcher.search(query, n_results)
        
        if not web_docs:
            logger.warning("âœ— No results found on web")
            return SearchResult(
                source="local",
                results=local_results or f"No results found for '{query}'"
            )
        
        # 3ë‹¨ê³„: ì›¹ ê²°ê³¼ í¬ë§·íŒ…
        logger.info(f"âœ“ Found {len(web_docs)} results from web")
        web_results = self._format_web_results(query, web_docs)
        
        # 4ë‹¨ê³„: ë°±ê·¸ë¼ìš´ë“œ ì¸ë±ì‹±
        logger.info(f"ğŸ“š Scheduling {len(web_docs)} documents for background indexing")
        asyncio.create_task(self._index_background(web_docs))
        
        return SearchResult(
            source="web",
            results=web_results,
            new_docs_count=len(web_docs)
        )
    
    async def _search_local(
        self, 
        query: str, 
        n: int
    ) -> Tuple[str, int]:
        """ë¡œì»¬ DB ê²€ìƒ‰"""
        try:
            results = await self.local_search.search(query, n)
            count = self._extract_count(results)
            return results, count
        except Exception as e:
            logger.error(f"Local search error: {e}")
            return "", 0
    
    async def _index_background(self, documents: list):
        """ë°±ê·¸ë¼ìš´ë“œ ì¸ë±ì‹±"""
        try:
            logger.info(f"â³ Background indexing started")
            await self.indexer.index_documents(documents)
            logger.info(f"âœ… Successfully indexed {len(documents)} documents")
        except Exception as e:
            logger.error(f"âŒ Background indexing failed: {e}")
    
    @staticmethod
    def _extract_count(markdown: str) -> int:
        """ë§ˆí¬ë‹¤ìš´ì—ì„œ ê²°ê³¼ ìˆ˜ ì¶”ì¶œ"""
        match = re.search(r"Total (\d+) documents found", markdown)
        return int(match.group(1)) if match else 0
    
    @staticmethod
    def _format_web_results(query: str, docs: list) -> str:
        """ì›¹ ê²€ìƒ‰ ê²°ê³¼ í¬ë§·íŒ…"""
        output = [
            f"# ğŸŒ Real-time Web Search: '{query}'",
            "",
            f"âš¡ **Live results** - Found {len(docs)} documents",
            "ğŸ“ *These results are being added to your database...*",
            "",
            "---",
            ""
        ]
        
        for i, doc in enumerate(docs, 1):
            output.extend([
                f"## {i}. [{doc.title}]({doc.url})",
                f"**Platform**: {doc.platform} | **Date**: {doc.date}",
                f"**Preview**: {doc.content[:200]}...",
                ""
            ])
        
        return "\n".join(output)
