import asyncio
import aiohttp
from bs4 import BeautifulSoup
import ssl
import certifi
import logging

logger = logging.getLogger(__name__)
ssl_context = ssl.create_default_context(cafile=certifi.where())

# ì—¬ëŸ¬ ìŠ¤í‚¨ ëŒ€ì‘ìš© ë³¸ë¬¸ í›„ë³´ ì„ íƒì
CONTENT_SELECTORS = [
    "div.entry-content",
    "div.article",
    "div.post-content",
    "div.tt_article_useless_p_margin",
    "div.contents_style",
    "div#content",
]

async def fetch_post(session, blog_name, post_id):
    url = f"https://{blog_name}.tistory.com/{post_id}"
    try:
        async with session.get(url, ssl=ssl_context, timeout=10) as resp:
            if resp.status != 200:
                logger.debug(f"âŒ {url} â†’ status {resp.status}")
                return None
            
            html = await resp.text()
            soup = BeautifulSoup(html, "html.parser")
            
            # ì œëª©
            h1 = soup.find("h1")
            title_tag = h1 or soup.find("meta", property="og:title")
            title = title_tag.get("content", "").strip() if title_tag and title_tag.name == "meta" else (title_tag.get_text(strip=True) if title_tag else f"Post {post_id}")
            
            # ì‘ì„±ì¼
            date_tag = soup.find("span", class_="date") or soup.find("time")
            date = date_tag.get_text(strip=True) if date_tag else ""
            
            # ë³¸ë¬¸ (ë‹¤ì–‘í•œ ìŠ¤í‚¨ ì§€ì›)
            content = ""
            for selector in CONTENT_SELECTORS:
                tag = soup.select_one(selector)
                if tag:
                    # ê´‘ê³ /ë¶ˆí•„ìš”í•œ ì˜ì—­ ì œê±°
                    for ad in tag.find_all(["div", "ins"], class_=["revenue_unit_wrap", "google-auto-placed"]):
                        ad.decompose()
                    content = tag.get_text(separator="\n", strip=True)
                    if content:
                        break
            
            if not content:
                logger.debug(f"âš ï¸ {url} â†’ ë³¸ë¬¸ íƒìƒ‰ ì‹¤íŒ¨")
                return None
            
            return {
                "id": str(post_id),
                "title": title,
                "url": url,
                "date": date,
                "content": content,
                "platform": "Tistory"
            }

    except Exception as e:
        logger.warning(f"ğŸš¨ {url} â†’ ìš”ì²­ ì‹¤íŒ¨: {e}")
        return None


async def fetch_tistory_posts(blog_name="silver-programmer", max_id=300):
    posts = []
    connector = aiohttp.TCPConnector(limit=10)
    timeout_config = aiohttp.ClientTimeout(total=10)

    async with aiohttp.ClientSession(
        connector=connector,
        timeout=timeout_config
    ) as session:
        tasks = [fetch_post(session, blog_name, i) for i in range(1, max_id + 1)]
        found_count = 0
        skipped_count = 0

        for i, future in enumerate(asyncio.as_completed(tasks), 1):
            post = await future
            if post:
                posts.append(post)
                found_count += 1
                if found_count % 10 == 0:
                    logger.info(f"ì§„í–‰ ì¤‘... {found_count}ê°œ í¬ìŠ¤íŠ¸ ë°œê²¬")
            else:
                skipped_count += 1

        logger.info(f"âœ… í¬ë¡¤ë§ ì™„ë£Œ: {found_count}ê°œ ë°œê²¬, {skipped_count}ê°œ ìŠ¤í‚µ")

    return posts
