from mcp.server.fastmcp import FastMCP
import logging
import asyncio
import hashlib
from llama_index.core import VectorStoreIndex, Document, StorageContext, Settings
from llama_index.vector_stores.chroma import ChromaVectorStore
from llama_index.core.retrievers import VectorIndexRetriever
from environments.config import setup_chroma
from posts.notion import fetch_notion_pages
from posts.tistory import fetch_tistory_posts

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# -----------------------------
# FastMCP ì„œë²„ ì´ˆê¸°í™”
# -----------------------------
mcp = FastMCP("content-search-server")

# -----------------------------
# Chroma ì„¤ì •
# -----------------------------
chroma_collection = setup_chroma()
vector_store = ChromaVectorStore(chroma_collection=chroma_collection)
storage_context = StorageContext.from_defaults(vector_store=vector_store)
Settings.cache_dir = ".llama_cache"

# -----------------------------
# ê¸€ë¡œë²Œ ìƒíƒœ ë³€ìˆ˜
# -----------------------------
index = None
index_status = {
    "state": "idle",       # idle, running, done, error
    "message": "",
    "progress": 0.0,       # 0.0 ~ 1.0
    "total_docs": 0,
    "processed_docs": 0
}

# -----------------------------
# í•´ì‹œ ìœ í‹¸
# -----------------------------
def get_content_hash(content: str) -> str:
    return hashlib.md5(content.encode("utf-8")).hexdigest()


# ================================================================
# ğŸŸ¡ 1ï¸âƒ£ ì¸ë±ì‹± íŠ¸ë¦¬ê±° (ì¦‰ì‹œ ì‘ë‹µ)
# ================================================================
@mcp.tool()
async def trigger_index_all_content() -> str:
    """
    ì¸ë±ì‹±ì„ ë°±ê·¸ë¼ìš´ë“œì—ì„œ ì‹œì‘í•©ë‹ˆë‹¤.
    ì¦‰ì‹œ ì‘ë‹µí•˜ë©°, ì§„í–‰ìƒí™©ì€ get_index_status()ë¡œ í™•ì¸í•˜ì„¸ìš”.

    Returns:
        str: ì¸ë±ì‹± ê²°ê³¼ ìš”ì•½
            - ìˆ˜ì§‘ëœ ë¬¸ì„œ ìˆ˜
            - ìƒì„±ëœ ì²­í¬ ìˆ˜
            - ì„±ê³µ/ì‹¤íŒ¨ ë©”ì‹œì§€
    """
    if index_status["state"] == "running":
        return "âš™ï¸ ì´ë¯¸ ì¸ë±ì‹±ì´ ì§„í–‰ ì¤‘ì…ë‹ˆë‹¤. ì ì‹œ í›„ ë‹¤ì‹œ í™•ì¸í•´ì£¼ì„¸ìš”."

    asyncio.create_task(index_all_content_background())
    return "ğŸŸ¡ ì¸ë±ì‹± ì‘ì—…ì„ ë°±ê·¸ë¼ìš´ë“œì—ì„œ ì‹œì‘í–ˆìŠµë‹ˆë‹¤. 'get_index_status'ë¡œ ìƒíƒœë¥¼ í™•ì¸í•˜ì„¸ìš”."


# ================================================================
# âš™ï¸ 2ï¸âƒ£ ì‹¤ì œ ì¸ë±ì‹± ë¡œì§ (ë°±ê·¸ë¼ìš´ë“œ)
# ================================================================
async def index_all_content_background():
    global index, index_status
    index_status.update({"state": "running", "message": "ë¬¸ì„œ ìˆ˜ì§‘ ì¤‘...", "progress": 0.0})
    try:
        # Step 1: ë¬¸ì„œ ìˆ˜ì§‘
        notion_docs = await fetch_notion_pages()
        tistory_docs = await fetch_tistory_posts()
        all_docs = (notion_docs or []) + (tistory_docs or [])

        total = len(all_docs)
        index_status["total_docs"] = total

        if not all_docs:
            index_status.update({"state": "done", "message": "âŒ ìˆ˜ì§‘ëœ ë¬¸ì„œê°€ ì—†ìŠµë‹ˆë‹¤.", "progress": 1.0})
            return

        # Step 2: ê¸°ì¡´ ì¸ë±ìŠ¤ ë¹„êµ
        existing_data = chroma_collection.get(include=["metadatas"])
        existing_docs = {
            metadata.get("doc_id"): metadata.get("content_hash", "")
            for metadata in existing_data["metadatas"]
        }

        new_or_updated_documents = []
        new_count, update_count = 0, 0

        for i, doc in enumerate(all_docs, 1):
            doc_id = doc["id"]
            content_hash = get_content_hash(doc["content"])

            if doc_id not in existing_docs:
                new_count += 1
            elif existing_docs[doc_id] != content_hash:
                update_count += 1
                chroma_collection.delete(where={"doc_id": doc_id})
            else:
                index_status["processed_docs"] = i
                index_status["progress"] = round(i / total, 2)
                continue

            new_or_updated_documents.append(
                Document(
                    text=doc["content"],
                    metadata={
                        "title": doc["title"],
                        "platform": doc["platform"],
                        "url": doc["url"],
                        "date": doc.get("date", ""),
                        "doc_id": doc_id,
                        "content_hash": content_hash,
                    },
                )
            )

            if i % 10 == 0:
                index_status["message"] = f"ì¸ë±ì‹± ì¤€ë¹„ ì¤‘... ({i}/{total})"
                index_status["progress"] = round(i / total, 2)
                await asyncio.sleep(0.01)

        # Step 3: ì¸ë±ì‹± ìˆ˜í–‰
        batch_size = 50
        index_status["message"] = "ë¬¸ì„œ ì¸ë±ì‹± ì¤‘..."

        for i in range(0, len(new_or_updated_documents), batch_size):
            batch = new_or_updated_documents[i : i + batch_size]

            if index is None:
                index = VectorStoreIndex.from_documents(batch, storage_context=storage_context, show_progress=True)
            else:
                for doc in batch:
                    index.insert(doc)

            index_status["processed_docs"] = min(total, i + batch_size)
            index_status["progress"] = round(index_status["processed_docs"] / total, 2)
            await asyncio.sleep(0.1)

        index_status.update({
            "state": "done",
            "message": f"âœ… ì¸ë±ì‹± ì™„ë£Œ (ì‹ ê·œ {new_count}ê°œ / ì—…ë°ì´íŠ¸ {update_count}ê°œ)",
            "progress": 1.0
        })
        logger.info(index_status["message"])

    except Exception as e:
        logger.error(f"ì¸ë±ì‹± ì˜¤ë¥˜: {e}")
        index_status.update({
            "state": "error",
            "message": f"âŒ ì¸ë±ì‹± ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}",
            "progress": 1.0
        })


# ================================================================
# ğŸ” 3ï¸âƒ£ ê²€ìƒ‰ ê¸°ëŠ¥ (ê¸°ì¡´ê³¼ ë™ì¼)
# ================================================================
@mcp.tool()
async def search_content(query: str, n_results: int = 10) -> str:
    """
    í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤.
    LlamaIndexì˜ ê³ ê¸‰ ê²€ìƒ‰ ê¸°ëŠ¥ì„ ì‚¬ìš©í•˜ì—¬ ë” ì •í™•í•œ ê²°ê³¼ë¥¼ ì œê³µí•©ë‹ˆë‹¤.
    
    Args:
        query: ê²€ìƒ‰í•  ë‚´ìš©
        n_results: ë°˜í™˜í•  ê²°ê³¼ ê°œìˆ˜
    """
    global index
    try:
        if index is None:
            index = VectorStoreIndex.from_vector_store(vector_store, storage_context=storage_context)

        retriever = VectorIndexRetriever(
            index=index,
            similarity_top_k=n_results * 2,
            vector_store_query_mode="hybrid",
        )

        nodes = retriever.retrieve(query)
        if not nodes:
            return f"'{query}'ì— ëŒ€í•œ ê²€ìƒ‰ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤."

        seen_titles = set()
        results = []
        for node in nodes:
            title = node.metadata.get("title", "Untitled")
            if title not in seen_titles:
                seen_titles.add(title)
                results.append({
                    "title": title,
                    "platform": node.metadata.get("platform", "Unknown"),
                    "url": node.metadata.get("url", ""),
                    "date": node.metadata.get("date", ""),
                    "score": node.score,
                    "text": node.text[:200] + "..."
                })
                if len(results) >= n_results:
                    break

        output = f"# ğŸ” ê²€ìƒ‰ ê²°ê³¼: '{query}'\n\nì´ {len(results)}ê°œì˜ ë¬¸ì„œë¥¼ ì°¾ì•˜ìŠµë‹ˆë‹¤.\n\n"
        for i, r in enumerate(results, 1):
            output += f"## {i}. [{r['title']}]({r['url']})\n"
            output += f"**í”Œë«í¼**: {r['platform']} | **ë‚ ì§œ**: {r['date']}\n"
            output += f"**ê´€ë ¨ë„**: {r['score']:.3f}\n"
            output += f"**ë¯¸ë¦¬ë³´ê¸°**: {r['text']}\n\n"

        return output

    except Exception as e:
        logger.error(f"ê²€ìƒ‰ ì˜¤ë¥˜: {e}")
        return f"âŒ ê²€ìƒ‰ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}"


# ================================================================
# ğŸ“Š 4ï¸âƒ£ ì¸ë±ì‹± ìƒíƒœ ì¡°íšŒ
# ================================================================
@mcp.tool()
async def get_index_status() -> dict:
    """
    í˜„ì¬ ì¸ë±ì‹± ìƒíƒœë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤.
    """
    return index_status


# ================================================================
# ğŸš€ ë©”ì¸ ì‹¤í–‰
# ================================================================
if __name__ == "__main__":
    mcp.run()
